{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd571f4-3d9b-439d-8b75-66c1c291c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf2094-c7c6-4add-b375-e52f6b328d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Bonaventure F. P. Dossou - bonaventure.dossou@mila.quebec (bonaventuredossou.github.io)\n",
    "# Data transformation, Models Configurations and Training (more details on Solution.md)\n",
    "# Check License under LICENSE.md\n",
    "\n",
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import resnet18, resnet50, resnet152, efficientnet_v2_m, convnext_base, wide_resnet101_2, vgg19_bn, regnet_x_32gf, swin_b, maxvit_t\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "os.environ['TORCH_HOME'] = os.path.join('/','home','ngsci','project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52790e-e8b2-4367-ab0f-8742c87872ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('/','home','ngsci','project', 'breast_cancer')\n",
    "print(data_dir)\n",
    "num_classes = 5\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "feature_extract = False\n",
    "num_gpus = [i for i in range(torch.cuda.device_count())]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if len(num_gpus) > 1:\n",
    "    print(\"Let's use\", len(num_gpus), \"GPUs!\")\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(str(x) for x in num_gpus)\n",
    "\n",
    "best_models = [\"efficientnet\", \"maxvit\", \"swin\", \"wide_resnet101\", \"vgg\", \"convnext\", \"resnet50\", \"regnet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9a556-02e6-4886-bf8c-190c7753e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ngsci\n",
    "import glob\n",
    "\n",
    "home = os.getenv(\"HOME\")\n",
    "contest_dir = os.path.join(home, \"datasets\", \"brca-psj-path\", \"contest-phase-2\")\n",
    "slide_manifest = pd.read_csv(os.path.join(contest_dir, \"slide-manifest-holdout.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8032f65a-22ec-4f09-a14f-5a0b8e6af53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openslide\n",
    "def downsample_slide(ndpi_filepath, output_dir, slide_id):\n",
    "    with openslide.OpenSlide(ndpi_filepath) as openslide_obj:\n",
    "        dim = openslide_obj.dimensions\n",
    "        new_dim = (224, 224)\n",
    "        image = openslide_obj.get_thumbnail(new_dim)\n",
    "        image.save(os.path.join(output_dir, f\"{slide_id}.png\"))\n",
    "\n",
    "def create_images_to_dir(dataset_split, data_paths):\n",
    "    directory = os.path.join('/','home','ngsci','project', 'breast_cancer', dataset_split)\n",
    "    total_data = len(data_paths)\n",
    "    for index in tqdm(range(total_data), desc =\"Data Creation Progress\"):\n",
    "        _slide_id, slide_path = data_paths[index]\n",
    "        downsample_slide(slide_path, directory, _slide_id)\n",
    "\n",
    "test_data_dir = os.path.join('/','home','ngsci', 'project', 'breast_cancer', 'test')\n",
    "test_slides_fp = os.path.join(test_data_dir,'*')\n",
    "test_slides_list = glob.glob(test_slides_fp)\n",
    "print('Eval Images: {}'.format(len(test_slides_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb040cd-8e09-4ef3-a9df-04fd6db58afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "def run_inference_image(path, model):\n",
    "    model.eval()\n",
    "    slide_id = path.split('/')[-1].split('.')[0]\n",
    "    image = Image.open(path)\n",
    "\n",
    "    transform_data = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.CenterCrop((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    \n",
    "    img_t = transform_data(image)\n",
    "    img_t = img_t.float().unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(img_t.to(device))\n",
    "    \n",
    "    prediction = output.squeeze(0).softmax(0)\n",
    "    class_id = prediction.argmax().item()\n",
    "    all_proba_class_id = prediction.cpu().numpy().tolist() + [class_id]\n",
    "    return slide_id, np.array(all_proba_class_id)\n",
    "\n",
    "def run_inference(paths, model):\n",
    "    predictions = []\n",
    "    for index in tqdm(range(len(paths)), desc =\"Evaluation Progress\"):\n",
    "        predictions.append(run_inference_image(paths[index], model))\n",
    "    pred_dict = {biopsy: preds for biopsy, preds in predictions}\n",
    "    return pred_dict\n",
    "\n",
    "def build_model(model_name):\n",
    "    \n",
    "    if model_name == \"resnet18\":\n",
    "        lr = 1e-5\n",
    "        model_ft = resnet18(weights=None)\n",
    "        checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 5)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "    \n",
    "    if model_name == \"resnet50\":\n",
    "        lr = 1e-4\n",
    "        model_ft = resnet50(weights=None)\n",
    "        checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 5)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "\n",
    "    if model_name == \"resnet152\":\n",
    "        lr = 1e-5\n",
    "        model_ft = resnet152(weights=None)\n",
    "        checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 5)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "    \n",
    "    if model_name == \"wide_resnet101\":\n",
    "        lr = 1e-4\n",
    "        model_ft = wide_resnet101_2(weights=None)\n",
    "        checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 5)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "\n",
    "    if model_name == \"vgg\":\n",
    "        lr = 1e-4\n",
    "        model_ft = vgg19_bn(weights=None)\n",
    "        checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, 5)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "    \n",
    "    if model_name == \"efficientnet\":\n",
    "        lr = 4e-4\n",
    "        model_ft = efficientnet_v2_m(weights=None)\n",
    "        checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier[1] = nn.Linear(num_ftrs, 5)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "\n",
    "    if model_name == \"efficientnet_l\":\n",
    "        lr = 4e-4\n",
    "        model_ft = efficientnet_v2_l(weights=None)\n",
    "        checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier[1] = nn.Linear(num_ftrs, 5)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "\n",
    "    if model_name == \"convnext\":\n",
    "        lr = 1e-5\n",
    "        model_ft = convnext_base(weights=None)\n",
    "        checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "        num_ftrs = model_ft.classifier[2].in_features\n",
    "        model_ft.classifier[2] = nn.Linear(num_ftrs, 5)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "\n",
    "    if model_name == \"regnet\":\n",
    "        lr = 1e-5\n",
    "        model_ft = regnet_x_32gf(weights=None)\n",
    "        checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 5)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "\n",
    "    if model_name == \"swin\":\n",
    "        lr = 1e-5\n",
    "        model_ft = swin_b(weights=None)\n",
    "        checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "        num_ftrs = model_ft.head.in_features\n",
    "        model_ft.head = nn.Linear(num_ftrs, 5)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "\n",
    "    if model_name == \"swin_v2_b\":\n",
    "        lr = 1e-5\n",
    "        model_ft = swin_v2_b(weights=None)\n",
    "        checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "        num_ftrs = model_ft.head.in_features\n",
    "        model_ft.head = nn.Linear(num_ftrs, 5)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "\n",
    "    if model_name == \"maxvit\":\n",
    "        lr = 1e-4\n",
    "        model_ft = maxvit_t(weights=None)\n",
    "        checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "        num_ftrs = model_ft.classifier[5].in_features\n",
    "        model_ft.classifier[5] = nn.Linear(num_ftrs, 5)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "\n",
    "def to_device(model):\n",
    "    if len(num_gpus) > 1:\n",
    "        model = torch.nn.DataParallel(model, device_ids=num_gpus)\n",
    "        model = model.module\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def save_predictions(pred_dict, name_model):\n",
    "    frame = pd.DataFrame()\n",
    "    frame['slide_id'] = list(pred_dict.keys())\n",
    "    preds = np.array(list(pred_dict.values()))\n",
    "    frame['prob_stage_0'] = preds[:, 0]\n",
    "    frame['prob_stage_1'] = preds[:, 1]\n",
    "    frame['prob_stage_2'] = preds[:, 2]\n",
    "    frame['prob_stage_3'] = preds[:, 3]\n",
    "    frame['prob_stage_4'] = preds[:, 4]\n",
    "    frame['stage_pred'] = preds[:, 5]\n",
    "    frame.to_csv('predictions/predictions_{}_{}_{}.csv'.format(name_model, batch_size, num_epochs), index=False)\n",
    "\n",
    "for model_ in best_models:\n",
    "    print('Predicting for {}'.format(model_))\n",
    "    predictions_dict = run_inference(test_slides_list, to_device(build_model(model_)))\n",
    "    save_predictions(predictions_dict, model_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da12082-0378-4ed0-9744-029eddf46950",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_ in best_models:\n",
    "    file_ = 'predictions/predictions_{}_{}_{}.csv'.format(model_, batch_size, num_epochs)\n",
    "    predictions_model = pd.read_csv(file_)\n",
    "    \n",
    "    biopsy_stage_prediction = (\n",
    "        predictions_model\n",
    "        .merge(slide_manifest)\n",
    "        .drop(columns=['slide_id','slide_path','patient_ngsci_id'])\n",
    "        .groupby(\"biopsy_id\")\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    biopsy_stage_prediction.to_csv('predictions/final_predictions_{}_{}_{}.csv'.format(model_, batch_size, num_epochs), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b96b29-27ef-4e23-a96a-16b5b85b82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gmean, tmean\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a76aab3-1937-44a9-b11d-8a3539513c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('predictions/final_predictions_{}_{}_{}.csv'.format(\"efficientnet\", batch_size, num_epochs))\n",
    "biopsy_ids = data.biopsy_id.tolist()\n",
    "final_frame = pd.DataFrame()\n",
    "final_frame['biopsy_id'] = biopsy_ids\n",
    "\n",
    "def get_model_column(model_name, column):\n",
    "    data = pd.read_csv('predictions/final_predictions_{}_{}_{}.csv'.format(model_name, batch_size, num_epochs))\n",
    "    return data[column].tolist()\n",
    "\n",
    "columns = ['prob_stage_0', 'prob_stage_1', 'prob_stage_2', 'prob_stage_3', 'prob_stage_4']\n",
    "\n",
    "for column in columns:\n",
    "    columns_geo_mean = []\n",
    "    for name_model in best_models:\n",
    "        columns_geo_mean.append(get_model_column(name_model, column))\n",
    "    \n",
    "    geo_mean = [gmean([efficientnet, maxvit, swin, wide_resnet101, vgg, convnext, resnet50, regnet]) *\n",
    "                tmean([efficientnet, maxvit, swin, wide_resnet101, vgg, convnext, resnet50, regnet])\n",
    "                for efficientnet, maxvit, swin, wide_resnet101, vgg, convnext, resnet50, regnet\n",
    "                in zip(*columns_geo_mean)]\n",
    "\n",
    "    final_frame[column] = geo_mean\n",
    "\n",
    "# normalize to get sum of proba -> 1\n",
    "final_frame[\"Sum\"] = final_frame.sum(axis=1)\n",
    "final_frame = final_frame.loc[:,\"prob_stage_0\":\"prob_stage_4\"].div(final_frame[\"Sum\"], axis=0)\n",
    "\n",
    "def column_to_index(x):\n",
    "    return columns.index(x)\n",
    "\n",
    "final_frame['biopsy_id'] = biopsy_ids\n",
    "cols = ['biopsy_id'] + columns\n",
    "final_frame = final_frame.loc[:, cols]\n",
    "stage_pred = []\n",
    "\n",
    "for _ in range(len(final_frame)):\n",
    "    stage_pred.append(np.argmax(final_frame.loc[_, :].values[1:]))\n",
    "\n",
    "final_frame['stage_pred'] = stage_pred\n",
    "final_frame.to_csv('predictions/preds_all_geo_times_arith_mean.csv', index=False, header=False)\n",
    "final_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed809c08-ed54-440f-9e53-8cec315d9e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ngsci\n",
    "submission_file = 'predictions/preds_all_geo_times_arith_mean.csv'\n",
    "ngsci.submit_contest_entry(submission_file, description=\"preds_all_geo_times_arith_mean\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
